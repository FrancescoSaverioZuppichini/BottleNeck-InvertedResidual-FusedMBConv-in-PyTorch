{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual, BottleNeck, Inverted Residual, Linear BottleNeck, MBConv Explained \n",
    "## What the hell are those + implementation in PyTorch\n",
    "\n",
    "Keeping track of names in modern Deep Learning is hard. Today we'll see different blocks used in modern CNN architecture such as ResNet, MobileNet, EfficientNet, and their implementation in PyTorch! \n",
    "\n",
    "\n",
    "**All these blocks have been implemented in my library [glasses](https://github.com/FrancescoSaverioZuppichini/glasses)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do anything, let's create a general conv - norm - act layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class ConvNormAct(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        kernel_size: int,\n",
    "        norm: nn.Module = nn.BatchNorm2d,\n",
    "        act: nn.Module = nn.ReLU,\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        super().__init__(\n",
    "            nn.Conv2d(\n",
    "                in_features,\n",
    "                out_features,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=kernel_size // 2,\n",
    "            ),\n",
    "            norm(out_features),\n",
    "            act(),\n",
    "        )\n",
    "\n",
    "\n",
    "Conv1X1BnReLU = partial(ConvNormAct, kernel_size=1)\n",
    "Conv3X3BnReLU = partial(ConvNormAct, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 56, 56])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn((1, 32, 56, 56))\n",
    "\n",
    "Conv1X1BnReLU(32, 64)(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Connections\n",
    "\n",
    "Residual connections were used in ResNet proposed in [*Deep Residual Learning for Image Recognition*](https://arxiv.org/abs/1512.03385) and let's also cite Schmidhuber lab's work on [*Highway networks*](https://arxiv.org/abs/1505.00387). The idea is to add your input to your output, `output = layer(input) + input`. The following image may help you visualize it. But, I mean it is just a `+` operator. The residual operation improves the ability of a gradient to propagate across multiplier layers permitting to effectively train networks with more than a hundred layers.\n",
    "\n",
    "![alt](./images/Residual.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, we can easily create a `ResidualAdd` Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 56, 56])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch import Tensor\n",
    "\n",
    "class ResidualAdd(nn.Module):\n",
    "    def __init__(self, block: nn.Module):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        res = x\n",
    "        x = self.block(x)\n",
    "        x += res\n",
    "        return x\n",
    "\n",
    "    \n",
    "ResidualAdd(\n",
    "    nn.Conv2d(32, 32, kernel_size=1)\n",
    ")(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortcut\n",
    "Sometimes your residual hasn't the same output's dimension, so we cannot add them. We can project the input using a conv in the shortcut (the black arrow with the +) to match your output's feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 56, 56])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class ResidualAdd(nn.Module):\n",
    "    def __init__(self, block: nn.Module, shortcut: Optional[nn.Module] = None):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.shortcut = shortcut\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        res = x\n",
    "        x = self.block(x)\n",
    "        if self.shortcut:\n",
    "            res = self.shortcut(res)\n",
    "        x += res\n",
    "        return x\n",
    "\n",
    "ResidualAdd(\n",
    "    nn.Conv2d(32, 64, kernel_size=1),\n",
    "    shortcut=nn.Conv2d(32, 64, kernel_size=1)\n",
    ")(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BottleNeck Blocks\n",
    "Bottlenecks blocks were also introduced in [*Deep Residual Learning for Image Recognition*](https://arxiv.org/abs/1512.03385). A BottleNeck block takes an input of size `BxCxHxW`, it first reduces it to `BxC/rxHxW` using an inexpensive `1x1 conv`, then applies a `3x3 conv` and finally remaps the output to the same feature dimension as the input, `BxCxHxW` using again a `1x1 conv`. This is faster than using three `3x3 convs`. Since the input is reduced first, this is why we called it \"BottleNeck\". The following figure visualizes the block, we used `r=4` as in the original implementation \n",
    "\n",
    "![alt](./images/BottleNeck.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two convs are followed by batchnorm and a non-linear activation, while the last non-linearity is applied after the addition. In PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 56, 56])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class BottleNeck(nn.Sequential):\n",
    "    def __init__(self, in_features: int, out_features: int, reduction: int = 4):\n",
    "        reduced_features = out_features // reduction\n",
    "        super().__init__(\n",
    "            nn.Sequential(\n",
    "                ResidualAdd(\n",
    "                    nn.Sequential(\n",
    "                        # wide -> narrow\n",
    "                        Conv1X1BnReLU(in_features, reduced_features),\n",
    "                        # narrow -> narrow\n",
    "                        Conv3X3BnReLU(reduced_features, reduced_features),\n",
    "                        # narrow -> wide\n",
    "                        Conv1X1BnReLU(reduced_features, out_features, act=nn.Identity),\n",
    "                    ),\n",
    "                    shortcut=Conv1X1BnReLU(in_features, out_features)\n",
    "                    if in_features != out_features\n",
    "                    else None,\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "BottleNeck(32, 64)(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we apply `shortcut` only if the input and output features are different.\n",
    "\n",
    "In practice a `stride=2` is used in the middle convolution when we wish to reduce the spatial dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear BottleNecks\n",
    "\n",
    "Linear BottleNecks were introduced in [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381). A Linear BottleNeck Block is a BottleNeck Block without the last activation. In the paper, section 3.2 they go into details about why having non-linearity before the output hurt performance. In a nutshell, the non-linearity function, line ReLU that sets everything < 0 to 0, destroys information. They have empirically shown that this is true when the input's channels are less than the output's. So, remove the `nn.ReLU` in the BottleNeck and you have it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted Residual\n",
    "\n",
    "Inverted Residuals were introduced, again, in [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381). Inverted Residual blocks are inverted BottleNeck layers. They expand features with the first conv instead of reducing them. The following image should make this clear\n",
    "\n",
    "\n",
    "![alt](./images/InvertedResidual.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we go from `BxCxHxW` to ->`BxCexHxW` -> `BxCexHxW` -> `BxCxHxW`, where `e` is the *expansion ratio* and it is set to `4`. Instead of going wide -> narrow -> wide as in normal bottleneck block, they do the opposite, narrow -> wide -> narrow. In PyTorch this is trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 56, 56])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class InvertedResidual(nn.Sequential):\n",
    "    def __init__(self, in_features: int, out_features: int, expansion: int = 4):\n",
    "        expanded_features = in_features * expansion\n",
    "        super().__init__(\n",
    "            nn.Sequential(\n",
    "                ResidualAdd(\n",
    "                    nn.Sequential(\n",
    "                        # narrow -> wide\n",
    "                        Conv1X1BnReLU(in_features, expanded_features),\n",
    "                        # wide -> wide\n",
    "                        Conv3X3BnReLU(expanded_features, expanded_features),\n",
    "                        # wide -> narrow\n",
    "                        Conv1X1BnReLU(expanded_features, out_features, act=nn.Identity),\n",
    "                    ),\n",
    "                    shortcut=Conv1X1BnReLU(in_features, out_features)\n",
    "                    if in_features != out_features\n",
    "                    else None,\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "InvertedResidual(32, 64)(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `MobileNet`residual connections are only applied when the input and output features match, don't ask me why, if you know it please comment :) So you should do something like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 56, 56])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MobileNetLikeBlock(nn.Sequential):\n",
    "    def __init__(self, in_features: int, out_features: int, expansion: int = 4):\n",
    "        # use ResidualAdd if features match, otherwise a normal Sequential\n",
    "        residual = ResidualAdd if in_features == out_features else nn.Sequential\n",
    "        expanded_features = in_features * expansion\n",
    "        super().__init__(\n",
    "            nn.Sequential(\n",
    "                residual(\n",
    "                    nn.Sequential(\n",
    "                        # narrow -> wide\n",
    "                        Conv1X1BnReLU(in_features, expanded_features),\n",
    "                        # wide -> wide\n",
    "                        Conv3X3BnReLU(expanded_features, expanded_features),\n",
    "                        # wide -> narrow\n",
    "                        Conv1X1BnReLU(expanded_features, out_features, act=nn.Identity),\n",
    "                    ),\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "MobileNetLikeBlock(32, 64)(x).shape\n",
    "MobileNetLikeBlock(32, 32)(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MBConv\n",
    "\n",
    "So after MobileNetV2, its building blocks were referred as `MBConv`. A `MBConv` is a Inverted Linear BottleNeck layer with Depth-Wise Separable Convolution. \n",
    "\n",
    "### Depth-Wise Separable Convolution\n",
    "Depth-Wise Separable Convolutions adopt a trick to splint a normal 3x3 conv in two convs to reduce the number of parameters. The first one applies a single 3x3 filter to each input's channels, the other applies a 1x1 filter to all the channels. If you do your match, this is the same thing as doing a normal 3x3 conv but you save parameters. \n",
    "\n",
    "This is also kind of stupid because it is way slower than a normal 3x3 on the current hardware we have. \n",
    "\n",
    "The following picture shows the idea\n",
    "\n",
    "![alt](./images/DepthwiseSeparableConv.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different colours in the channels represent one individual filter applied per channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 54, 54])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DepthWiseSeparableConv(nn.Sequential):\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(in_features, in_features, kernel_size=3, groups=in_features),\n",
    "            nn.Conv2d(in_features, out_features, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "DepthWiseSeparableConv(32, 64)(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first convolution is usually called `depth` while the second `point`. Let's count the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2432"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in DepthWiseSeparableConv(32, 64).parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a normal Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18496"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in nn.Conv2d(32, 64, kernel_size=3).parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a big difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the MBConv\n",
    "So, let's create a full MBConv. There are a couple of MBConv's important details, normalization is applied to both depth and point convolution and non-linearity only in the depth convolution (remember linear bottlenecks). The applied ReLU6 non-linearity. Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 56, 56])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MBConv(nn.Sequential):\n",
    "    def __init__(self, in_features: int, out_features: int, expansion: int = 4):\n",
    "        residual = ResidualAdd if in_features == out_features else nn.Sequential\n",
    "        expanded_features = in_features * expansion\n",
    "        super().__init__(\n",
    "            nn.Sequential(\n",
    "                residual(\n",
    "                    nn.Sequential(\n",
    "                        # narrow -> wide\n",
    "                        Conv1X1BnReLU(in_features, \n",
    "                                      expanded_features,\n",
    "                                      act=nn.ReLU6\n",
    "                                     ),\n",
    "                        # wide -> wide\n",
    "                        Conv3X3BnReLU(expanded_features, \n",
    "                                      expanded_features, \n",
    "                                      groups=expanded_features,\n",
    "                                      act=nn.ReLU6\n",
    "                                     ),\n",
    "                        # here you can apply SE\n",
    "                        # wide -> narrow\n",
    "                        Conv1X1BnReLU(expanded_features, out_features, act=nn.Identity),\n",
    "                    ),\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "MBConv(32, 64)(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slighly modified version of this block, with [Squeeze and Excitation](https://arxiv.org/abs/1709.01507) is used in [EfficientNet](https://arxiv.org/abs/1905.11946)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fused Inverted Residual (Fused MBConv)\n",
    "\n",
    "Fused Inverted Residuals were introduced in [EfficientNetV2: Smaller Models and Faster Training](https://arxiv.org/abs/2104.00298) to make MBConv faster. So basically, since Depthwise convolutions are slow, they fused the first and second conv in a single 3x3 conv (section 3.2). \n",
    "\n",
    "![alt](./images/FusedInvertedResidual.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 56, 56])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FusedMBConv(nn.Sequential):\n",
    "    def __init__(self, in_features: int, out_features: int, expansion: int = 4):\n",
    "        residual = ResidualAdd if in_features == out_features else nn.Sequential\n",
    "        expanded_features = in_features * expansion\n",
    "        super().__init__(\n",
    "            nn.Sequential(\n",
    "                residual(\n",
    "                    nn.Sequential(\n",
    "                        Conv3X3BnReLU(in_features, \n",
    "                                      expanded_features, \n",
    "                                      act=nn.ReLU6\n",
    "                                     ),\n",
    "                        # here you can apply SE\n",
    "                        # wide -> narrow\n",
    "                        Conv1X1BnReLU(expanded_features, out_features, act=nn.Identity),\n",
    "                    ),\n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "MBConv(32, 64)(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Now you should know the difference between all these blocks and the reasoning behind them! I highly reccomand reading the paper realted to them, you can't go wrong with that. \n",
    "\n",
    "For a more detailed guide to ResNet, check out [Residual Networks: Implementing ResNet in Pytorch](https://towardsdatascience.com/residual-network-implementing-resnet-a7da63c7b278)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
